# Pinecone Configuration
# Get your API key from: https://app.pinecone.io/
PINECONE_API_KEY=your-pinecone-api-key-here
# Your Pinecone environment (e.g., gcp-starter for free tier, us-west1-gcp for GCP)
# Find this in your Pinecone Console dashboard under Project Settings
PINECONE_ENVIRONMENT=us-east1-gcp
# Name for your vector index
PINECONE_INDEX_NAME=your-index-name-here

# Google AI Configuration
# Get your API key from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=your-google-api-key-here

# Model Configuration
# Available models: gemini-pro, gemini-pro-vision
MODEL_NAME=gemini-pro
# Embedding model for vector creation
EMBEDDING_MODEL=text-embedding-004

# Document Processing Settings
# Size of text chunks when splitting documents
CHUNK_SIZE=1000
# Overlap between chunks to maintain context
CHUNK_OVERLAP=200

# Optional: Application Settings
# Temperature for LLM responses (0.0 to 1.0)
TEMPERATURE=0.7
# Maximum number of tokens in response
MAX_OUTPUT_TOKENS=2048

# Google Cloud credentials
GOOGLE_APPLICATION_CREDENTIALS=/path/to/your/service-account-key.json
GOOGLE_PROJECT_ID=your-project-id
GOOGLE_CLIENT_EMAIL=your-service-account-email

# Hello World Example Settings
# These are the minimum required variables for helloRedwood.py
# PINECONE_API_KEY=your-pinecone-api-key-here
# PINECONE_ENVIRONMENT=your-pinecone-environment-here 